{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DggNMz9GdisD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img, array_to_img\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP4lFsRwNabr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlBuKgoUfya4"
      },
      "source": [
        "load the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VJuuitH7dKU"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/GANS_files/smalldata'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ0tOHen2Hoi"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_paths = []\n",
        "for image_name in os.listdir(BASE_DIR):\n",
        "    image_path = os.path.join(BASE_DIR, image_name)\n",
        "    image_paths.append(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPRS6bjQ3kGN"
      },
      "outputs": [],
      "source": [
        "len(image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crZUyVRe3soq"
      },
      "outputs": [],
      "source": [
        "# to display grid of images (7x7)\n",
        "plt.figure(figsize=(20, 20))\n",
        "temp_images = image_paths[:49]\n",
        "index = 1\n",
        "for image_path in temp_images:\n",
        "    plt.subplot(7, 7, index)\n",
        "    # load the image\n",
        "    img = load_img(image_path)\n",
        "    img = np.array(img)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    # increment the index for next image\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHZZuH_251oH"
      },
      "source": [
        "visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkjJOu1c5VAI"
      },
      "outputs": [],
      "source": [
        "# load the image and convert to numpy array\n",
        "train_images = [np.array(load_img(path, color_mode=\"grayscale\")) for path in tqdm(image_paths)]\n",
        "train_images = np.array(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkxcdvlb566z"
      },
      "outputs": [],
      "source": [
        "train_images[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Oda_xSBSYb"
      },
      "outputs": [],
      "source": [
        "# reshape the array\n",
        "train_images = train_images.reshape(train_images.shape[0], 64, 64, 1).astype('float16')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES6BLsQguisX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# normalize the images\n",
        "train_images = train_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cLbJpOj-dPO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0PsnOa13u8i"
      },
      "outputs": [],
      "source": [
        "LATENT_DIM = 100\n",
        "WEIGHT_INIT = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS-YvB5AUv__"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = Sequential(name='generator')\n",
        "\n",
        "# 1d random noise\n",
        "model.add(layers.Dense(8 * 8 * 512, input_dim=LATENT_DIM))\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "#  1d to 3d\n",
        "model.add(layers.Reshape((8, 8, 512)))\n",
        "\n",
        "# upsample to 16x16\n",
        "model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "# upsample to 32x32\n",
        "model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "# upsample to 64x64\n",
        "model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "model.add(layers.Conv2D(CHANNELS, (4, 4), padding='same', activation='tanh'))\n",
        "\n",
        "generator = model\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5vI_ELtUyep"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = Sequential(name='discriminator')\n",
        "input_shape = (64, 64, 1)\n",
        "alpha = 0.2\n",
        "\n",
        "# create conv layers\n",
        "model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "\n",
        "model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "\n",
        "model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.LeakyReLU(alpha=alpha))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "# output class\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "discriminator = model\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSHKu-frU1fi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create DCGAN\n",
        "\n",
        "class DCGAN(keras.Model):\n",
        "    def __init__(self, generator, discriminator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
        "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.g_loss_metric, self.d_loss_metric]\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
        "        super(DCGAN, self).compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # get batch size from the data\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        # generate random noise\n",
        "        random_noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # train the discriminator with real (1) and fake (0) images\n",
        "        with tf.GradientTape() as tape:\n",
        "            # compute loss on real images\n",
        "            pred_real = self.discriminator(real_images, training=True)\n",
        "            real_labels = tf.ones((batch_size, 1))\n",
        "            # label smoothing\n",
        "            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels))\n",
        "            d_loss_real = self.loss_fn(real_labels, pred_real)\n",
        "\n",
        "            # compute loss on fake images\n",
        "            fake_images = self.generator(random_noise)\n",
        "            pred_fake = self.discriminator(fake_images, training=True)\n",
        "            # generate fake labels\n",
        "            fake_labels = tf.zeros((batch_size, 1))\n",
        "            d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
        "\n",
        "            # total discriminator loss\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "\n",
        "        # compute discriminator gradients\n",
        "        gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "        # update the gradients\n",
        "        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "        # train the generator model\n",
        "        labels = tf.ones((batch_size, 1))\n",
        "        with tf.GradientTape() as tape:\n",
        "            # generate fake images from generator\n",
        "            fake_images = self.generator(random_noise, training=True)\n",
        "            # classify images as real or fake\n",
        "            pred_fake = self.discriminator(fake_images, training=True)\n",
        "            # compute loss\n",
        "            g_loss = self.loss_fn(labels, pred_fake)\n",
        "\n",
        "        # compute gradients\n",
        "        gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        # update the gradients\n",
        "        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n",
        "\n",
        "        # update states for both models\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "        return {'d_loss': self.d_loss_metric.result(), 'g_loss': self.g_loss_metric.result()}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsd8YBbTU4J7"
      },
      "outputs": [],
      "source": [
        "class DCGANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_imgs=25, latent_dim=100):\n",
        "        self.num_imgs = num_imgs\n",
        "        self.latent_dim = latent_dim\n",
        "        # create random noise for generating images\n",
        "        self.noise = tf.random.normal([25, latent_dim])\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # generate the image from noise\n",
        "        g_img = self.model.generator(self.noise)\n",
        "        # denormalize the image\n",
        "        g_img = (g_img ) + 255\n",
        "        g_img.numpy()\n",
        "\n",
        "        fig = plt.figure(figsize=(8, 8))\n",
        "        for i in range(self.num_imgs):\n",
        "            plt.subplot(5, 5, i+1)\n",
        "            img = array_to_img(g_img[i])\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.axis('off')\n",
        "        # plt.savefig('epoch_{:03d}.png'.format(epoch))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeDdvbKOtar1"
      },
      "outputs": [],
      "source": [
        "  def on_train_end(self, logs=None):\n",
        "        self.model.generator.save('generator.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-X2d0GUM2aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dcgan = DCGAN(generator=generator, discriminator=discriminator, latent_dim=LATENT_DIM)\n",
        "D_LR = 0.0001\n",
        "G_LR = 0.0001\n",
        "dcgan.compile(g_optimizer=Adam(learning_rate=G_LR, beta_1=0.9), d_optimizer=Adam(learning_rate=D_LR, beta_1=0.9), loss_fn=BinaryCrossentropy())\n",
        "\n"
      ],
      "metadata": {
        "id": "34JODqxuKwy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model\n",
        "N_EPOCHS = 50\n",
        "checkpoint_callback = ModelCheckpoint(filepath='/content/drive/MyDrive/generator_checkpoints/generator_epoch_{epoch:02d}.h5', save_freq=100, save_weights_only=True)\n",
        "dcgan.fit(train_images, epochs=N_EPOCHS, callbacks=[DCGANMonitor(), checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "iZnkHwQ7K2xj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}